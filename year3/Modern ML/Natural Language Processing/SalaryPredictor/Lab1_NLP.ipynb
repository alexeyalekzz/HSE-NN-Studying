{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV1ljHdskiD8"
      },
      "source": [
        "# Лабораторная работа № 1. Обработка естественного языка.\n",
        "Вам нужно будет взять [ноутбук](https://drive.google.com/file/d/1euxnmvVeE5byHiTd-axQz4pF9wgEHXmQ/view?usp=sharing) с предсказанием заработной платы, который  Вы разбирали на практике, и улучшить его.\n",
        "\n",
        "Несколько советов по оформлениею работы:\n",
        "*   В начале ноутбука добавьте небольшое резюме - что Вами было сделано в ноутбуке: что попробовали, какие результаты получили.\n",
        "*   Все эксперементы оформите с графиками функции потерь и метриками MAE, MSE. Графики постройте на тренировочных, тестовых и валидационных данных. В конце каждого эксперемента выведите лучшие значения.\n",
        "*   В конце каждого эксперемента напишите свои выводы. Подкрепите их визуализацией и/или метриками.\n",
        "\n",
        "**Дедлайн 23 апреля 23:59 МСК**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ALdajmNlMgt"
      },
      "source": [
        "**1. Развейте СNN архитектуру (2 балла)**\n",
        "\n",
        "Добавьте в пайплайн\n",
        "\n",
        "*   Batch Norm (nn.BatchNorm), LayerNorm...\n",
        "*   Параллельные сверточные слои. Идея в том, чтобы применить несколько nn.Conv1d к одному и тому же эмбеддингу и после этого сконкатенировать выходные каналы\n",
        "*   Больше слоев...\n",
        "*   Добавьте раннюю остановку\n",
        "\n",
        "На каких примерах модели ведут себя максимально различно/похоже? Предположите с чем это может быть связано. \n",
        "\n",
        "Как модель ведет себя в зависимости от количества обучаемых параметров?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAOrDf5BrPYg"
      },
      "source": [
        "**2. Pooling слои стандартные (1 балла)**\n",
        "\n",
        "*   Опишите своими словами как работает Pooling слой.\n",
        "*   Взять максимум по временной компоненте (незавимисо для каждой фичи)\n",
        "*   Взять среднее по временной компоненте (исключая PAD символы)\n",
        "\n",
        "Применять можно к любой архитектуре (CNN/RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvUDIsPwthQw"
      },
      "source": [
        "**3. Используйте предобученные эмбеддинги (2 балла)**\n",
        "\n",
        "*   Загрузите предобученные эмбеддинги с помощью gensim.downloader.load\n",
        "*   Используйте метод [from_pretrained](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) слоя torch.nn.Embedding для инициализации эмбеддингов с помощью предобученных весов. Можете попбровать несколько типов предобученных эмбеддингов.\n",
        "*   Проведите эксперементы с обучаемыми/замороженными весами эмбеддингов.\n",
        "Используйте одни и те же эмбеддинги для Title и FullDescription.\n",
        "\n",
        "Сравните результаты:\n",
        "1.   Эмбеддингов, инициализируемых случайно из $$\\mathcal{N}(0,1)$$ (по умолчанию у слоя torch.nn.Embedding)\n",
        "2.   Предобученных эмбеддингов с замороженными весами\n",
        "3.   Предобученных эмбеддингов с обучаемыми весами\n",
        "\n",
        "Что изменяется в поведении модели? Какой эксперимент дал лучший результат?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeXqZdS9w1YZ"
      },
      "source": [
        "**4. Замените сверточные слои на рекуррентные (3 балла)**\n",
        "\n",
        "* Замените сверточне слоим рекуррентными LSTM/GRU.\n",
        "* Проведите эксперимент с однонаправленной и двунаправленной рекуррентной нейросетью\n",
        "* Попробуйте найти удачный микс рекуррентных и сверточных слоев. Попробуйте разные миксы для Title и FullDescription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr7dzpHC0BBC"
      },
      "source": [
        "**5. Вытащите признаки из нейронной сети и используйте их в ансамбле деревьев решений. (2 балла)**\n",
        "\n",
        "* Вытащите признаки с предпоследнего слоя обученной нейросети и передайте их в ансамбль деревьев решений.\n",
        "* Сравните результаты работы лучшей нейросети и ансамбля деревьев решений, построенном на признаках из этой нейросети. Сможет ли замена последнего слоя на ансамбль деревьев решений улучшить результат?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M0QpozBs4TQ"
      },
      "source": [
        "**6. Pooling слои продвинутые* (3 балла)**\n",
        "\n",
        "Реализуйте и примените\n",
        "Softmax-pooling:$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
        "\n",
        "Attentive pooling$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
        "\n",
        ", где $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$и $NN_{attn}$ полносвязный слой.\n"
      ]
    }
  ]
}